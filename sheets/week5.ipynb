{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MATH50003 Numerical Analysis: Problem Sheet 5\n\nThis problem sheet explores positive definite matrices,\nCholesky decompositions, matrix norms, and the singular value decomposition.\n\nQuestions marked with a ⋆ are meant to be completed without using a computer.\nProblems are denoted A/B/C to indicate their difficulty."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using LinearAlgebra, Plots, Test"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Positive definite matrices and Cholesky decompositions\n\n\n**Problem 1.1⋆ (C)** Use the Cholesky decomposition to determine\nwhich of the following matrices are symmetric positive definite:\n$$\n\\begin{bmatrix} 1 & -1  \\\\\n-1 & 3\n\\end{bmatrix}, \\begin{bmatrix} 1 & 2 & 2  \\\\\n2 & 1 & 2\\\\\n2 & 2 & 1\n\\end{bmatrix}, \\begin{bmatrix} 3 & 2 & 1  \\\\\n2 & 4 & 2\\\\\n1 & 2 & 5\n\\end{bmatrix}, \n\\begin{bmatrix} 4 & 2 & 2 & 1  \\\\\n2 & 4 & 2 & 2\\\\\n2 & 2 & 4 & 2 \\\\\n1 & 2 & 2 & 4\n\\end{bmatrix}\n$$\n\n\n\n**Problem 1.2⋆ (B)** Recall that an inner product $⟨𝐱, 𝐲⟩$ on $ℝ^n$\nover the reals $ℝ$ satisfies, for all $𝐱,𝐲,𝐳 ∈ ℝ$ and $a,b ∈ ℝ$:\n1. Symmetry: $⟨𝐱, 𝐲⟩ = ⟨𝐲, 𝐱⟩$\n2. Linearity: $⟨a𝐱+b𝐲, 𝐳⟩ = a ⟨𝐱, 𝐳⟩+ b⟨𝐲, 𝐳⟩$\n3. Posive-definite: $⟨𝐱, 𝐱⟩ > 0$\nProve that $⟨𝐱, 𝐲⟩$ is an inner product if and only if\n$$\n⟨𝐱, 𝐲⟩ = 𝐱^⊤ K 𝐲\n$$\nwhere $K$ is a symmetric positive definite matrix.\n\n\n\n**Problem 1.3⋆ (A)** Show that a matrix is symmetric positive definite if and only if it has a Cholesky\ndecomposition of the form\n$$\nA = U U^⊤\n$$\nwhere $U$ is upper triangular with positive entries on the diagonal.\n\n\n\n**Problem 1.4⋆ (A)** Prove that the following $n × n$ matrix is symmetric positive definite\nfor any $n$:\n$$\nΔ_n := \\begin{bmatrix}\n2 & -1 \\\\\n-1 & 2 & -1 \\\\\n& -1 & 2 & ⋱ \\\\\n&& ⋱ & ⋱ & -1 \\\\\n&&& -1 & 2\n\\end{bmatrix}\n$$\nDeduce its two Cholesky decompositions: $Δ_n = L_n L_n^⊤ = U_n U_n^⊤$ where\n$L_n$ is lower triangular and $U_n$ is upper triangular.\n\n\n\n**Problem 1.5 (B)** `SymTridiagonal(dv, eu)` is a type for representing symmetric tridiagonal\nmatrices (that is, `SymTridiagonal(dv, ev) == Tridiagonal(ev, dv, ev)`). Complete the following\nimplementation of `cholesky` to return a `Bidiagonal` cholesky factor in $O(n)$ operations, \nand check your result\ncompared to your solution of Problem 1.3 for `n = 1_000_000`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "import LinearAlgebra: cholesky\n\n# return a Bidiagonal L such that L'L == A (up to machine precision)\ncholesky(A::SymTridiagonal) = cholesky!(copy(A))\n\n# return a Bidiagonal L such that L'L == A (up to machine precision)\n# You are allowed to change A\nfunction cholesky!(A::SymTridiagonal)\n    d = A.dv # diagonal entries of A\n    u = A.ev # sub/super-diagonal entries of A\n    T = float(eltype(A)) # return type, make float in case A has Ints\n    n = length(d)\n    ld = zeros(T, n) # diagonal entries of L\n    ll = zeros(T, n-1) # sub-diagonal entries of L\n\n    Bidiagonal(ld, ll, :L)\nend\n\nn = 1000\nA = SymTridiagonal(2*ones(n),-ones(n-1))\nL = cholesky(A)\n@test L ≈ cholesky(Matrix(A)).L"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Matrix norms\n\n**Problem 2.1⋆ (B)** Prove the following:\n$$\n\\begin{align*}\n\\|A\\|_∞ &= \\max_k \\|A[k,:]\\|_1 \\\\\n\\|A\\|_{1 → ∞} &= \\|\\hbox{vec}(A)\\|_∞ = \\max_{kj} |a_{kj}|\n\\end{align*}\n$$\n\n\n\n\n**Problem 2.2⋆ (B)** For a rank-1 matrix $A = 𝐱 𝐲^⊤$ prove that\n$$\n\\|A \\|_2 = \\|𝐱\\|_2 \\|𝐲\\|_2.\n$$\nHint: use the Cauchy–Schwartz inequality.\n\n\n\n**Problem 2.3⋆ (B)** Show for any orthogonal matrix $Q ∈ ℝ^m$ and\nmatrix $A ∈ ℝ^{m × n}$ that\n$$\n\\|Q A\\|_F = \\|A\\|_F\n$$\nby first showing that $\\|A \\|_F = \\sqrt{\\hbox{tr}(A^⊤ A)}$ using the\n_trace_ of an $m × m$ matrix:\n$$\n\\hbox{tr}(A) = a_{11} + a_{22} + ⋯ + a_{mm}.\n$$\n\n\n\n## 3. Singular value decomposition\n\n**Problem 3.1⋆ (B)** Show that $\\|A \\|_2 ≤ \\|A\\|_F ≤ \\sqrt{r} \\|A \\|_2$ where\n$r$ is the rank of $A$.\n\n\n\n**Problem 3.2 (A)** Consider functions sampled on a $(n+1) × (n+1)$ 2D grid \n$(x_k,y_j) = (k/n, j/n)$ where $k,j = 0,…,n$. \nFor $n = 100$, what is the lowest rank $r$ such that\nthe  best rank-$r$ approximation to the samples \nthat is accurate to within $10^{-5}$ accuracy for the following functions:\n$$\n(x + 2y)^2, \\cos(\\sin x {\\rm e}^y), 1/(x + y + 1), \\hbox{sign}(x-y)\n$$\nFor which examples does the answer change when $n = 1000$?\n\n\n\n**Problem 3.3⋆ (B)** For $A ∈ ℝ^{m × n}$ define the _pseudo-inverse_:\n$$\nA^+ := V Σ^{-1} U^⊤.\n$$\nShow that it satisfies the _Moore-Penrose conditions_:\n1. $A A^+ A = A$\n2. $A^+ A A^+ = A^+$\n3. $(A A^+)^⊤  = A A^+$ and $(A^+ A)^⊤ = A^+ A$\n\n\n\n**Problem 3.4⋆ (A)** Show for $A ∈ ℝ^{m × n}$ with $m ≥ n$ and ⊤ rank\nthat $𝐱 =  A^+ 𝐛$ is the least squares solution, i.e., minimises $\\| A 𝐱 - 𝐛 \\|_2$.\nHint: extend $U$ in the SVD to be a square orthogonal matrix.\n\n\n\n**Problem 3.5⋆ (A)**\nIf $A ∈ ℝ^{m × n}$ has a non-empty kernel there are multiple solutions to the least\nsquares problem as \nwe can add any element of the kernel. Show that $𝐱 = A^+ 𝐛$ gives the least squares solution\nsuch that $\\| 𝐱 \\|_2$ is minimised."
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.7.0"
    },
    "kernelspec": {
      "name": "julia-1.7",
      "display_name": "Julia 1.7.0",
      "language": "julia"
    }
  },
  "nbformat": 4
}
